{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "23520046.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyoman123/Pembelajaran-Mesin/blob/master/NLP1%20TOOLS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvJVuPWxVbVF"
      },
      "source": [
        "# I Nyoman Switrayana-23520046"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h4ldi9vVbVJ"
      },
      "source": [
        "#Menginstal library dan menunduh package data NLTK"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMI8VohbVbVM",
        "outputId": "3a2fd55b-2e5c-4fb3-8c49-d95d051b129e"
      },
      "source": [
        "!pip3 install nltk\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in c:\\users\\nyoman switrayana\\anaconda3\\lib\\site-packages (3.5)\n",
            "Requirement already satisfied: joblib in c:\\users\\nyoman switrayana\\anaconda3\\lib\\site-packages (from nltk) (0.16.0)\n",
            "Requirement already satisfied: regex in c:\\users\\nyoman switrayana\\anaconda3\\lib\\site-packages (from nltk) (2020.6.8)\n",
            "Requirement already satisfied: tqdm in c:\\users\\nyoman switrayana\\anaconda3\\lib\\site-packages (from nltk) (4.47.0)\n",
            "Requirement already satisfied: click in c:\\users\\nyoman switrayana\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYY6EwUqVbVN",
        "outputId": "67f837e5-a8bf-4938-b058-ced4a399619a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to C:\\Users\\Nyoman\n",
            "[nltk_data]     Switrayana\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\Nyoman\n",
            "[nltk_data]     Switrayana\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Nyoman\n",
            "[nltk_data]     Switrayana\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to C:\\Users\\Nyoman\n",
            "[nltk_data]     Switrayana\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to C:\\Users\\Nyoman\n",
            "[nltk_data]     Switrayana\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTGqZo2BVbVO"
      },
      "source": [
        "# Sentence Splitter\n",
        "Memecah paragraf berdasarkan kalimat-kalimat yang terdapat didalamnya dengan determiner sebagai penanda akhir kalimat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn5dvK2nVbVP"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize as st"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXsJoNBhVbVQ",
        "outputId": "195cc6c7-d97a-4940-f553-d6c7ab84695e"
      },
      "source": [
        "sentence=\"NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum. Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation, NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike. NLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.NLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,” and “an amazing library to play with natural language.”Natural Language Processing with Python provides a practical introduction to programming for language processing. Written by the creators of NLTK, it guides the reader through the fundamentals of writing Python programs, working with corpora, categorizing text, analyzing linguistic structure, and more. The online version of the book has been been updated for Python 3 and NLTK 3. \"\n",
        "print(sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum. Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation, NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike. NLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.NLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,” and “an amazing library to play with natural language.”Natural Language Processing with Python provides a practical introduction to programming for language processing. Written by the creators of NLTK, it guides the reader through the fundamentals of writing Python programs, working with corpora, categorizing text, analyzing linguistic structure, and more. The online version of the book has been been updated for Python 3 and NLTK 3. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCUMQfj_VbVZ",
        "outputId": "8a4d4347-c1fa-4187-dc3e-57268fa4e651"
      },
      "source": [
        "sentence_splitter=st(sentence)\n",
        "print(sentence_splitter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NLTK is a leading platform for building Python programs to work with human language data.', 'It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.', 'Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation, NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike.', 'NLTK is available for Windows, Mac OS X, and Linux.', 'Best of all, NLTK is a free, open source, community-driven project.NLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,” and “an amazing library to play with natural language.”Natural Language Processing with Python provides a practical introduction to programming for language processing.', 'Written by the creators of NLTK, it guides the reader through the fundamentals of writing Python programs, working with corpora, categorizing text, analyzing linguistic structure, and more.', 'The online version of the book has been been updated for Python 3 and NLTK 3.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qkg3f6fVbVa"
      },
      "source": [
        "# Tokenization\n",
        "Memecah teks ke level kata(1 kata:unigram, 2 kata:bigrams, 3 kata:trigrams, n kata:ngrams)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzXmlpTYVbVa",
        "outputId": "e250dea3-518e-48d3-95dd-cbfcc5443e09"
      },
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "tokenization=word_tokenize(sentence) #tokenisasi unigram/per token\n",
        "print (tokenization)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NLTK', 'is', 'a', 'leading', 'platform', 'for', 'building', 'Python', 'programs', 'to', 'work', 'with', 'human', 'language', 'data', '.', 'It', 'provides', 'easy-to-use', 'interfaces', 'to', 'over', '50', 'corpora', 'and', 'lexical', 'resources', 'such', 'as', 'WordNet', ',', 'along', 'with', 'a', 'suite', 'of', 'text', 'processing', 'libraries', 'for', 'classification', ',', 'tokenization', ',', 'stemming', ',', 'tagging', ',', 'parsing', ',', 'and', 'semantic', 'reasoning', ',', 'wrappers', 'for', 'industrial-strength', 'NLP', 'libraries', ',', 'and', 'an', 'active', 'discussion', 'forum', '.', 'Thanks', 'to', 'a', 'hands-on', 'guide', 'introducing', 'programming', 'fundamentals', 'alongside', 'topics', 'in', 'computational', 'linguistics', ',', 'plus', 'comprehensive', 'API', 'documentation', ',', 'NLTK', 'is', 'suitable', 'for', 'linguists', ',', 'engineers', ',', 'students', ',', 'educators', ',', 'researchers', ',', 'and', 'industry', 'users', 'alike', '.', 'NLTK', 'is', 'available', 'for', 'Windows', ',', 'Mac', 'OS', 'X', ',', 'and', 'Linux', '.', 'Best', 'of', 'all', ',', 'NLTK', 'is', 'a', 'free', ',', 'open', 'source', ',', 'community-driven', 'project.NLTK', 'has', 'been', 'called', '“', 'a', 'wonderful', 'tool', 'for', 'teaching', ',', 'and', 'working', 'in', ',', 'computational', 'linguistics', 'using', 'Python', ',', '”', 'and', '“', 'an', 'amazing', 'library', 'to', 'play', 'with', 'natural', 'language.', '”', 'Natural', 'Language', 'Processing', 'with', 'Python', 'provides', 'a', 'practical', 'introduction', 'to', 'programming', 'for', 'language', 'processing', '.', 'Written', 'by', 'the', 'creators', 'of', 'NLTK', ',', 'it', 'guides', 'the', 'reader', 'through', 'the', 'fundamentals', 'of', 'writing', 'Python', 'programs', ',', 'working', 'with', 'corpora', ',', 'categorizing', 'text', ',', 'analyzing', 'linguistic', 'structure', ',', 'and', 'more', '.', 'The', 'online', 'version', 'of', 'the', 'book', 'has', 'been', 'been', 'updated', 'for', 'Python', '3', 'and', 'NLTK', '3', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goKaVA5-VbVb",
        "outputId": "1f118fa4-e28c-4007-ccae-fbe65b4854bc"
      },
      "source": [
        "from nltk.util import bigrams, trigrams, ngrams\n",
        "bigram=list(nltk.bigrams(tokenization)) #tokenisasi bigrams\n",
        "print (bigram, '\\n=====================================\\n\\n')\n",
        "trigram=list(nltk.trigrams(tokenization))#tokenisasi trigrams\n",
        "print (trigram, '\\n=====================================\\n\\n')\n",
        "ngram=list(nltk.ngrams(tokenization,5)) #tokenisasi ngrams (n=5 kata)\n",
        "print (ngram, '\\n=====================================\\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('NLTK', 'is'), ('is', 'a'), ('a', 'leading'), ('leading', 'platform'), ('platform', 'for'), ('for', 'building'), ('building', 'Python'), ('Python', 'programs'), ('programs', 'to'), ('to', 'work'), ('work', 'with'), ('with', 'human'), ('human', 'language'), ('language', 'data'), ('data', '.'), ('.', 'It'), ('It', 'provides'), ('provides', 'easy-to-use'), ('easy-to-use', 'interfaces'), ('interfaces', 'to'), ('to', 'over'), ('over', '50'), ('50', 'corpora'), ('corpora', 'and'), ('and', 'lexical'), ('lexical', 'resources'), ('resources', 'such'), ('such', 'as'), ('as', 'WordNet'), ('WordNet', ','), (',', 'along'), ('along', 'with'), ('with', 'a'), ('a', 'suite'), ('suite', 'of'), ('of', 'text'), ('text', 'processing'), ('processing', 'libraries'), ('libraries', 'for'), ('for', 'classification'), ('classification', ','), (',', 'tokenization'), ('tokenization', ','), (',', 'stemming'), ('stemming', ','), (',', 'tagging'), ('tagging', ','), (',', 'parsing'), ('parsing', ','), (',', 'and'), ('and', 'semantic'), ('semantic', 'reasoning'), ('reasoning', ','), (',', 'wrappers'), ('wrappers', 'for'), ('for', 'industrial-strength'), ('industrial-strength', 'NLP'), ('NLP', 'libraries'), ('libraries', ','), (',', 'and'), ('and', 'an'), ('an', 'active'), ('active', 'discussion'), ('discussion', 'forum'), ('forum', '.'), ('.', 'Thanks'), ('Thanks', 'to'), ('to', 'a'), ('a', 'hands-on'), ('hands-on', 'guide'), ('guide', 'introducing'), ('introducing', 'programming'), ('programming', 'fundamentals'), ('fundamentals', 'alongside'), ('alongside', 'topics'), ('topics', 'in'), ('in', 'computational'), ('computational', 'linguistics'), ('linguistics', ','), (',', 'plus'), ('plus', 'comprehensive'), ('comprehensive', 'API'), ('API', 'documentation'), ('documentation', ','), (',', 'NLTK'), ('NLTK', 'is'), ('is', 'suitable'), ('suitable', 'for'), ('for', 'linguists'), ('linguists', ','), (',', 'engineers'), ('engineers', ','), (',', 'students'), ('students', ','), (',', 'educators'), ('educators', ','), (',', 'researchers'), ('researchers', ','), (',', 'and'), ('and', 'industry'), ('industry', 'users'), ('users', 'alike'), ('alike', '.'), ('.', 'NLTK'), ('NLTK', 'is'), ('is', 'available'), ('available', 'for'), ('for', 'Windows'), ('Windows', ','), (',', 'Mac'), ('Mac', 'OS'), ('OS', 'X'), ('X', ','), (',', 'and'), ('and', 'Linux'), ('Linux', '.'), ('.', 'Best'), ('Best', 'of'), ('of', 'all'), ('all', ','), (',', 'NLTK'), ('NLTK', 'is'), ('is', 'a'), ('a', 'free'), ('free', ','), (',', 'open'), ('open', 'source'), ('source', ','), (',', 'community-driven'), ('community-driven', 'project.NLTK'), ('project.NLTK', 'has'), ('has', 'been'), ('been', 'called'), ('called', '“'), ('“', 'a'), ('a', 'wonderful'), ('wonderful', 'tool'), ('tool', 'for'), ('for', 'teaching'), ('teaching', ','), (',', 'and'), ('and', 'working'), ('working', 'in'), ('in', ','), (',', 'computational'), ('computational', 'linguistics'), ('linguistics', 'using'), ('using', 'Python'), ('Python', ','), (',', '”'), ('”', 'and'), ('and', '“'), ('“', 'an'), ('an', 'amazing'), ('amazing', 'library'), ('library', 'to'), ('to', 'play'), ('play', 'with'), ('with', 'natural'), ('natural', 'language.'), ('language.', '”'), ('”', 'Natural'), ('Natural', 'Language'), ('Language', 'Processing'), ('Processing', 'with'), ('with', 'Python'), ('Python', 'provides'), ('provides', 'a'), ('a', 'practical'), ('practical', 'introduction'), ('introduction', 'to'), ('to', 'programming'), ('programming', 'for'), ('for', 'language'), ('language', 'processing'), ('processing', '.'), ('.', 'Written'), ('Written', 'by'), ('by', 'the'), ('the', 'creators'), ('creators', 'of'), ('of', 'NLTK'), ('NLTK', ','), (',', 'it'), ('it', 'guides'), ('guides', 'the'), ('the', 'reader'), ('reader', 'through'), ('through', 'the'), ('the', 'fundamentals'), ('fundamentals', 'of'), ('of', 'writing'), ('writing', 'Python'), ('Python', 'programs'), ('programs', ','), (',', 'working'), ('working', 'with'), ('with', 'corpora'), ('corpora', ','), (',', 'categorizing'), ('categorizing', 'text'), ('text', ','), (',', 'analyzing'), ('analyzing', 'linguistic'), ('linguistic', 'structure'), ('structure', ','), (',', 'and'), ('and', 'more'), ('more', '.'), ('.', 'The'), ('The', 'online'), ('online', 'version'), ('version', 'of'), ('of', 'the'), ('the', 'book'), ('book', 'has'), ('has', 'been'), ('been', 'been'), ('been', 'updated'), ('updated', 'for'), ('for', 'Python'), ('Python', '3'), ('3', 'and'), ('and', 'NLTK'), ('NLTK', '3'), ('3', '.')] \n",
            "=====================================\n",
            "\n",
            "\n",
            "[('NLTK', 'is', 'a'), ('is', 'a', 'leading'), ('a', 'leading', 'platform'), ('leading', 'platform', 'for'), ('platform', 'for', 'building'), ('for', 'building', 'Python'), ('building', 'Python', 'programs'), ('Python', 'programs', 'to'), ('programs', 'to', 'work'), ('to', 'work', 'with'), ('work', 'with', 'human'), ('with', 'human', 'language'), ('human', 'language', 'data'), ('language', 'data', '.'), ('data', '.', 'It'), ('.', 'It', 'provides'), ('It', 'provides', 'easy-to-use'), ('provides', 'easy-to-use', 'interfaces'), ('easy-to-use', 'interfaces', 'to'), ('interfaces', 'to', 'over'), ('to', 'over', '50'), ('over', '50', 'corpora'), ('50', 'corpora', 'and'), ('corpora', 'and', 'lexical'), ('and', 'lexical', 'resources'), ('lexical', 'resources', 'such'), ('resources', 'such', 'as'), ('such', 'as', 'WordNet'), ('as', 'WordNet', ','), ('WordNet', ',', 'along'), (',', 'along', 'with'), ('along', 'with', 'a'), ('with', 'a', 'suite'), ('a', 'suite', 'of'), ('suite', 'of', 'text'), ('of', 'text', 'processing'), ('text', 'processing', 'libraries'), ('processing', 'libraries', 'for'), ('libraries', 'for', 'classification'), ('for', 'classification', ','), ('classification', ',', 'tokenization'), (',', 'tokenization', ','), ('tokenization', ',', 'stemming'), (',', 'stemming', ','), ('stemming', ',', 'tagging'), (',', 'tagging', ','), ('tagging', ',', 'parsing'), (',', 'parsing', ','), ('parsing', ',', 'and'), (',', 'and', 'semantic'), ('and', 'semantic', 'reasoning'), ('semantic', 'reasoning', ','), ('reasoning', ',', 'wrappers'), (',', 'wrappers', 'for'), ('wrappers', 'for', 'industrial-strength'), ('for', 'industrial-strength', 'NLP'), ('industrial-strength', 'NLP', 'libraries'), ('NLP', 'libraries', ','), ('libraries', ',', 'and'), (',', 'and', 'an'), ('and', 'an', 'active'), ('an', 'active', 'discussion'), ('active', 'discussion', 'forum'), ('discussion', 'forum', '.'), ('forum', '.', 'Thanks'), ('.', 'Thanks', 'to'), ('Thanks', 'to', 'a'), ('to', 'a', 'hands-on'), ('a', 'hands-on', 'guide'), ('hands-on', 'guide', 'introducing'), ('guide', 'introducing', 'programming'), ('introducing', 'programming', 'fundamentals'), ('programming', 'fundamentals', 'alongside'), ('fundamentals', 'alongside', 'topics'), ('alongside', 'topics', 'in'), ('topics', 'in', 'computational'), ('in', 'computational', 'linguistics'), ('computational', 'linguistics', ','), ('linguistics', ',', 'plus'), (',', 'plus', 'comprehensive'), ('plus', 'comprehensive', 'API'), ('comprehensive', 'API', 'documentation'), ('API', 'documentation', ','), ('documentation', ',', 'NLTK'), (',', 'NLTK', 'is'), ('NLTK', 'is', 'suitable'), ('is', 'suitable', 'for'), ('suitable', 'for', 'linguists'), ('for', 'linguists', ','), ('linguists', ',', 'engineers'), (',', 'engineers', ','), ('engineers', ',', 'students'), (',', 'students', ','), ('students', ',', 'educators'), (',', 'educators', ','), ('educators', ',', 'researchers'), (',', 'researchers', ','), ('researchers', ',', 'and'), (',', 'and', 'industry'), ('and', 'industry', 'users'), ('industry', 'users', 'alike'), ('users', 'alike', '.'), ('alike', '.', 'NLTK'), ('.', 'NLTK', 'is'), ('NLTK', 'is', 'available'), ('is', 'available', 'for'), ('available', 'for', 'Windows'), ('for', 'Windows', ','), ('Windows', ',', 'Mac'), (',', 'Mac', 'OS'), ('Mac', 'OS', 'X'), ('OS', 'X', ','), ('X', ',', 'and'), (',', 'and', 'Linux'), ('and', 'Linux', '.'), ('Linux', '.', 'Best'), ('.', 'Best', 'of'), ('Best', 'of', 'all'), ('of', 'all', ','), ('all', ',', 'NLTK'), (',', 'NLTK', 'is'), ('NLTK', 'is', 'a'), ('is', 'a', 'free'), ('a', 'free', ','), ('free', ',', 'open'), (',', 'open', 'source'), ('open', 'source', ','), ('source', ',', 'community-driven'), (',', 'community-driven', 'project.NLTK'), ('community-driven', 'project.NLTK', 'has'), ('project.NLTK', 'has', 'been'), ('has', 'been', 'called'), ('been', 'called', '“'), ('called', '“', 'a'), ('“', 'a', 'wonderful'), ('a', 'wonderful', 'tool'), ('wonderful', 'tool', 'for'), ('tool', 'for', 'teaching'), ('for', 'teaching', ','), ('teaching', ',', 'and'), (',', 'and', 'working'), ('and', 'working', 'in'), ('working', 'in', ','), ('in', ',', 'computational'), (',', 'computational', 'linguistics'), ('computational', 'linguistics', 'using'), ('linguistics', 'using', 'Python'), ('using', 'Python', ','), ('Python', ',', '”'), (',', '”', 'and'), ('”', 'and', '“'), ('and', '“', 'an'), ('“', 'an', 'amazing'), ('an', 'amazing', 'library'), ('amazing', 'library', 'to'), ('library', 'to', 'play'), ('to', 'play', 'with'), ('play', 'with', 'natural'), ('with', 'natural', 'language.'), ('natural', 'language.', '”'), ('language.', '”', 'Natural'), ('”', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', 'with'), ('Processing', 'with', 'Python'), ('with', 'Python', 'provides'), ('Python', 'provides', 'a'), ('provides', 'a', 'practical'), ('a', 'practical', 'introduction'), ('practical', 'introduction', 'to'), ('introduction', 'to', 'programming'), ('to', 'programming', 'for'), ('programming', 'for', 'language'), ('for', 'language', 'processing'), ('language', 'processing', '.'), ('processing', '.', 'Written'), ('.', 'Written', 'by'), ('Written', 'by', 'the'), ('by', 'the', 'creators'), ('the', 'creators', 'of'), ('creators', 'of', 'NLTK'), ('of', 'NLTK', ','), ('NLTK', ',', 'it'), (',', 'it', 'guides'), ('it', 'guides', 'the'), ('guides', 'the', 'reader'), ('the', 'reader', 'through'), ('reader', 'through', 'the'), ('through', 'the', 'fundamentals'), ('the', 'fundamentals', 'of'), ('fundamentals', 'of', 'writing'), ('of', 'writing', 'Python'), ('writing', 'Python', 'programs'), ('Python', 'programs', ','), ('programs', ',', 'working'), (',', 'working', 'with'), ('working', 'with', 'corpora'), ('with', 'corpora', ','), ('corpora', ',', 'categorizing'), (',', 'categorizing', 'text'), ('categorizing', 'text', ','), ('text', ',', 'analyzing'), (',', 'analyzing', 'linguistic'), ('analyzing', 'linguistic', 'structure'), ('linguistic', 'structure', ','), ('structure', ',', 'and'), (',', 'and', 'more'), ('and', 'more', '.'), ('more', '.', 'The'), ('.', 'The', 'online'), ('The', 'online', 'version'), ('online', 'version', 'of'), ('version', 'of', 'the'), ('of', 'the', 'book'), ('the', 'book', 'has'), ('book', 'has', 'been'), ('has', 'been', 'been'), ('been', 'been', 'updated'), ('been', 'updated', 'for'), ('updated', 'for', 'Python'), ('for', 'Python', '3'), ('Python', '3', 'and'), ('3', 'and', 'NLTK'), ('and', 'NLTK', '3'), ('NLTK', '3', '.')] \n",
            "=====================================\n",
            "\n",
            "\n",
            "[('NLTK', 'is', 'a', 'leading', 'platform'), ('is', 'a', 'leading', 'platform', 'for'), ('a', 'leading', 'platform', 'for', 'building'), ('leading', 'platform', 'for', 'building', 'Python'), ('platform', 'for', 'building', 'Python', 'programs'), ('for', 'building', 'Python', 'programs', 'to'), ('building', 'Python', 'programs', 'to', 'work'), ('Python', 'programs', 'to', 'work', 'with'), ('programs', 'to', 'work', 'with', 'human'), ('to', 'work', 'with', 'human', 'language'), ('work', 'with', 'human', 'language', 'data'), ('with', 'human', 'language', 'data', '.'), ('human', 'language', 'data', '.', 'It'), ('language', 'data', '.', 'It', 'provides'), ('data', '.', 'It', 'provides', 'easy-to-use'), ('.', 'It', 'provides', 'easy-to-use', 'interfaces'), ('It', 'provides', 'easy-to-use', 'interfaces', 'to'), ('provides', 'easy-to-use', 'interfaces', 'to', 'over'), ('easy-to-use', 'interfaces', 'to', 'over', '50'), ('interfaces', 'to', 'over', '50', 'corpora'), ('to', 'over', '50', 'corpora', 'and'), ('over', '50', 'corpora', 'and', 'lexical'), ('50', 'corpora', 'and', 'lexical', 'resources'), ('corpora', 'and', 'lexical', 'resources', 'such'), ('and', 'lexical', 'resources', 'such', 'as'), ('lexical', 'resources', 'such', 'as', 'WordNet'), ('resources', 'such', 'as', 'WordNet', ','), ('such', 'as', 'WordNet', ',', 'along'), ('as', 'WordNet', ',', 'along', 'with'), ('WordNet', ',', 'along', 'with', 'a'), (',', 'along', 'with', 'a', 'suite'), ('along', 'with', 'a', 'suite', 'of'), ('with', 'a', 'suite', 'of', 'text'), ('a', 'suite', 'of', 'text', 'processing'), ('suite', 'of', 'text', 'processing', 'libraries'), ('of', 'text', 'processing', 'libraries', 'for'), ('text', 'processing', 'libraries', 'for', 'classification'), ('processing', 'libraries', 'for', 'classification', ','), ('libraries', 'for', 'classification', ',', 'tokenization'), ('for', 'classification', ',', 'tokenization', ','), ('classification', ',', 'tokenization', ',', 'stemming'), (',', 'tokenization', ',', 'stemming', ','), ('tokenization', ',', 'stemming', ',', 'tagging'), (',', 'stemming', ',', 'tagging', ','), ('stemming', ',', 'tagging', ',', 'parsing'), (',', 'tagging', ',', 'parsing', ','), ('tagging', ',', 'parsing', ',', 'and'), (',', 'parsing', ',', 'and', 'semantic'), ('parsing', ',', 'and', 'semantic', 'reasoning'), (',', 'and', 'semantic', 'reasoning', ','), ('and', 'semantic', 'reasoning', ',', 'wrappers'), ('semantic', 'reasoning', ',', 'wrappers', 'for'), ('reasoning', ',', 'wrappers', 'for', 'industrial-strength'), (',', 'wrappers', 'for', 'industrial-strength', 'NLP'), ('wrappers', 'for', 'industrial-strength', 'NLP', 'libraries'), ('for', 'industrial-strength', 'NLP', 'libraries', ','), ('industrial-strength', 'NLP', 'libraries', ',', 'and'), ('NLP', 'libraries', ',', 'and', 'an'), ('libraries', ',', 'and', 'an', 'active'), (',', 'and', 'an', 'active', 'discussion'), ('and', 'an', 'active', 'discussion', 'forum'), ('an', 'active', 'discussion', 'forum', '.'), ('active', 'discussion', 'forum', '.', 'Thanks'), ('discussion', 'forum', '.', 'Thanks', 'to'), ('forum', '.', 'Thanks', 'to', 'a'), ('.', 'Thanks', 'to', 'a', 'hands-on'), ('Thanks', 'to', 'a', 'hands-on', 'guide'), ('to', 'a', 'hands-on', 'guide', 'introducing'), ('a', 'hands-on', 'guide', 'introducing', 'programming'), ('hands-on', 'guide', 'introducing', 'programming', 'fundamentals'), ('guide', 'introducing', 'programming', 'fundamentals', 'alongside'), ('introducing', 'programming', 'fundamentals', 'alongside', 'topics'), ('programming', 'fundamentals', 'alongside', 'topics', 'in'), ('fundamentals', 'alongside', 'topics', 'in', 'computational'), ('alongside', 'topics', 'in', 'computational', 'linguistics'), ('topics', 'in', 'computational', 'linguistics', ','), ('in', 'computational', 'linguistics', ',', 'plus'), ('computational', 'linguistics', ',', 'plus', 'comprehensive'), ('linguistics', ',', 'plus', 'comprehensive', 'API'), (',', 'plus', 'comprehensive', 'API', 'documentation'), ('plus', 'comprehensive', 'API', 'documentation', ','), ('comprehensive', 'API', 'documentation', ',', 'NLTK'), ('API', 'documentation', ',', 'NLTK', 'is'), ('documentation', ',', 'NLTK', 'is', 'suitable'), (',', 'NLTK', 'is', 'suitable', 'for'), ('NLTK', 'is', 'suitable', 'for', 'linguists'), ('is', 'suitable', 'for', 'linguists', ','), ('suitable', 'for', 'linguists', ',', 'engineers'), ('for', 'linguists', ',', 'engineers', ','), ('linguists', ',', 'engineers', ',', 'students'), (',', 'engineers', ',', 'students', ','), ('engineers', ',', 'students', ',', 'educators'), (',', 'students', ',', 'educators', ','), ('students', ',', 'educators', ',', 'researchers'), (',', 'educators', ',', 'researchers', ','), ('educators', ',', 'researchers', ',', 'and'), (',', 'researchers', ',', 'and', 'industry'), ('researchers', ',', 'and', 'industry', 'users'), (',', 'and', 'industry', 'users', 'alike'), ('and', 'industry', 'users', 'alike', '.'), ('industry', 'users', 'alike', '.', 'NLTK'), ('users', 'alike', '.', 'NLTK', 'is'), ('alike', '.', 'NLTK', 'is', 'available'), ('.', 'NLTK', 'is', 'available', 'for'), ('NLTK', 'is', 'available', 'for', 'Windows'), ('is', 'available', 'for', 'Windows', ','), ('available', 'for', 'Windows', ',', 'Mac'), ('for', 'Windows', ',', 'Mac', 'OS'), ('Windows', ',', 'Mac', 'OS', 'X'), (',', 'Mac', 'OS', 'X', ','), ('Mac', 'OS', 'X', ',', 'and'), ('OS', 'X', ',', 'and', 'Linux'), ('X', ',', 'and', 'Linux', '.'), (',', 'and', 'Linux', '.', 'Best'), ('and', 'Linux', '.', 'Best', 'of'), ('Linux', '.', 'Best', 'of', 'all'), ('.', 'Best', 'of', 'all', ','), ('Best', 'of', 'all', ',', 'NLTK'), ('of', 'all', ',', 'NLTK', 'is'), ('all', ',', 'NLTK', 'is', 'a'), (',', 'NLTK', 'is', 'a', 'free'), ('NLTK', 'is', 'a', 'free', ','), ('is', 'a', 'free', ',', 'open'), ('a', 'free', ',', 'open', 'source'), ('free', ',', 'open', 'source', ','), (',', 'open', 'source', ',', 'community-driven'), ('open', 'source', ',', 'community-driven', 'project.NLTK'), ('source', ',', 'community-driven', 'project.NLTK', 'has'), (',', 'community-driven', 'project.NLTK', 'has', 'been'), ('community-driven', 'project.NLTK', 'has', 'been', 'called'), ('project.NLTK', 'has', 'been', 'called', '“'), ('has', 'been', 'called', '“', 'a'), ('been', 'called', '“', 'a', 'wonderful'), ('called', '“', 'a', 'wonderful', 'tool'), ('“', 'a', 'wonderful', 'tool', 'for'), ('a', 'wonderful', 'tool', 'for', 'teaching'), ('wonderful', 'tool', 'for', 'teaching', ','), ('tool', 'for', 'teaching', ',', 'and'), ('for', 'teaching', ',', 'and', 'working'), ('teaching', ',', 'and', 'working', 'in'), (',', 'and', 'working', 'in', ','), ('and', 'working', 'in', ',', 'computational'), ('working', 'in', ',', 'computational', 'linguistics'), ('in', ',', 'computational', 'linguistics', 'using'), (',', 'computational', 'linguistics', 'using', 'Python'), ('computational', 'linguistics', 'using', 'Python', ','), ('linguistics', 'using', 'Python', ',', '”'), ('using', 'Python', ',', '”', 'and'), ('Python', ',', '”', 'and', '“'), (',', '”', 'and', '“', 'an'), ('”', 'and', '“', 'an', 'amazing'), ('and', '“', 'an', 'amazing', 'library'), ('“', 'an', 'amazing', 'library', 'to'), ('an', 'amazing', 'library', 'to', 'play'), ('amazing', 'library', 'to', 'play', 'with'), ('library', 'to', 'play', 'with', 'natural'), ('to', 'play', 'with', 'natural', 'language.'), ('play', 'with', 'natural', 'language.', '”'), ('with', 'natural', 'language.', '”', 'Natural'), ('natural', 'language.', '”', 'Natural', 'Language'), ('language.', '”', 'Natural', 'Language', 'Processing'), ('”', 'Natural', 'Language', 'Processing', 'with'), ('Natural', 'Language', 'Processing', 'with', 'Python'), ('Language', 'Processing', 'with', 'Python', 'provides'), ('Processing', 'with', 'Python', 'provides', 'a'), ('with', 'Python', 'provides', 'a', 'practical'), ('Python', 'provides', 'a', 'practical', 'introduction'), ('provides', 'a', 'practical', 'introduction', 'to'), ('a', 'practical', 'introduction', 'to', 'programming'), ('practical', 'introduction', 'to', 'programming', 'for'), ('introduction', 'to', 'programming', 'for', 'language'), ('to', 'programming', 'for', 'language', 'processing'), ('programming', 'for', 'language', 'processing', '.'), ('for', 'language', 'processing', '.', 'Written'), ('language', 'processing', '.', 'Written', 'by'), ('processing', '.', 'Written', 'by', 'the'), ('.', 'Written', 'by', 'the', 'creators'), ('Written', 'by', 'the', 'creators', 'of'), ('by', 'the', 'creators', 'of', 'NLTK'), ('the', 'creators', 'of', 'NLTK', ','), ('creators', 'of', 'NLTK', ',', 'it'), ('of', 'NLTK', ',', 'it', 'guides'), ('NLTK', ',', 'it', 'guides', 'the'), (',', 'it', 'guides', 'the', 'reader'), ('it', 'guides', 'the', 'reader', 'through'), ('guides', 'the', 'reader', 'through', 'the'), ('the', 'reader', 'through', 'the', 'fundamentals'), ('reader', 'through', 'the', 'fundamentals', 'of'), ('through', 'the', 'fundamentals', 'of', 'writing'), ('the', 'fundamentals', 'of', 'writing', 'Python'), ('fundamentals', 'of', 'writing', 'Python', 'programs'), ('of', 'writing', 'Python', 'programs', ','), ('writing', 'Python', 'programs', ',', 'working'), ('Python', 'programs', ',', 'working', 'with'), ('programs', ',', 'working', 'with', 'corpora'), (',', 'working', 'with', 'corpora', ','), ('working', 'with', 'corpora', ',', 'categorizing'), ('with', 'corpora', ',', 'categorizing', 'text'), ('corpora', ',', 'categorizing', 'text', ','), (',', 'categorizing', 'text', ',', 'analyzing'), ('categorizing', 'text', ',', 'analyzing', 'linguistic'), ('text', ',', 'analyzing', 'linguistic', 'structure'), (',', 'analyzing', 'linguistic', 'structure', ','), ('analyzing', 'linguistic', 'structure', ',', 'and'), ('linguistic', 'structure', ',', 'and', 'more'), ('structure', ',', 'and', 'more', '.'), (',', 'and', 'more', '.', 'The'), ('and', 'more', '.', 'The', 'online'), ('more', '.', 'The', 'online', 'version'), ('.', 'The', 'online', 'version', 'of'), ('The', 'online', 'version', 'of', 'the'), ('online', 'version', 'of', 'the', 'book'), ('version', 'of', 'the', 'book', 'has'), ('of', 'the', 'book', 'has', 'been'), ('the', 'book', 'has', 'been', 'been'), ('book', 'has', 'been', 'been', 'updated'), ('has', 'been', 'been', 'updated', 'for'), ('been', 'been', 'updated', 'for', 'Python'), ('been', 'updated', 'for', 'Python', '3'), ('updated', 'for', 'Python', '3', 'and'), ('for', 'Python', '3', 'and', 'NLTK'), ('Python', '3', 'and', 'NLTK', '3'), ('3', 'and', 'NLTK', '3', '.')] \n",
            "=====================================\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8JT8kKoVbVc"
      },
      "source": [
        "# Stemming\n",
        "Proses pemetaan dan penguraian bentuk dari suatu kata menjadi bentuk kata dasarnya atau proses mengurangi infleksi pada kata-kata menjadi bentuk akarnya seperti memetakan sekelompok kata ke stem yang sama bahkan jika stem itu sendiri bukan kata yang valid dalam Bahasanya."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyg6CxYoVbVe",
        "outputId": "6ab9796e-2089-4d7d-d399-602b01fb9b1a"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer=PorterStemmer()\n",
        "texts=[\"Affectation\",\"Affects\",\"Affections\",\"Affected\",\"Affection\",\"Affecting\",\"give\",\"giving\",\"given\",\"gave\"]\n",
        "texts2=[\"writes\",\"writing\",\"written\",\"wrote\"]\n",
        "#texts = [[word.lower() for word in line.split()] for line in words]\n",
        "#for word in texts:\n",
        "#    print(word+ \":\" +stemmer.stem(texts))\n",
        "text = [stemmer.stem(word) for word in texts] \n",
        "text2= [stemmer.stem(word) for word in texts2]\n",
        "print(text)\n",
        "print(text2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['affect', 'affect', 'affect', 'affect', 'affect', 'affect', 'give', 'give', 'given', 'gave']\n",
            "['write', 'write', 'written', 'wrote']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s5RrKMZVbVg"
      },
      "source": [
        "# Lemmatization\n",
        "\n",
        "Lemmatisasi, tidak seperti Stemming, mengurangi kata-kata yang dibelokkan dengan benar untuk memastikan bahwa akar kata milik bahasa tersebut. Dalam kata dasar Lemmatization disebut Lemma. Lemma (lemmas jamak atau lemmata) adalah bentuk kanonik, bentuk kamus, atau bentuk kutipan dari sekumpulan kata."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jztykokVbVi",
        "outputId": "592128e2-586e-459a-aee2-287f0916bc8d"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "texts1=[\"writes\",\"writing\",\"written\",\"wrote\"]\n",
        "text1 = [wordnet_lemmatizer.lemmatize(word, \"v\") for word in texts1]\n",
        "print(text1, \"\\n\\n\\n\")\n",
        "\n",
        "punctuations=\"?:!.,;\"\n",
        "sentence_words = nltk.word_tokenize(sentence)\n",
        "for word in sentence_words:\n",
        "    if word in punctuations:\n",
        "        sentence_words.remove(word)\n",
        "\n",
        "sentence_words\n",
        "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
        "for word in sentence_words:\n",
        "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['write', 'write', 'write', 'write'] \n",
            "\n",
            "\n",
            "\n",
            "Word                Lemma               \n",
            "NLTK                NLTK                \n",
            "is                  is                  \n",
            "a                   a                   \n",
            "leading             leading             \n",
            "platform            platform            \n",
            "for                 for                 \n",
            "building            building            \n",
            "Python              Python              \n",
            "programs            program             \n",
            "to                  to                  \n",
            "work                work                \n",
            "with                with                \n",
            "human               human               \n",
            "language            language            \n",
            "data                data                \n",
            "It                  It                  \n",
            "provides            provides            \n",
            "easy-to-use         easy-to-use         \n",
            "interfaces          interface           \n",
            "to                  to                  \n",
            "over                over                \n",
            "50                  50                  \n",
            "corpora             corpus              \n",
            "and                 and                 \n",
            "lexical             lexical             \n",
            "resources           resource            \n",
            "such                such                \n",
            "as                  a                   \n",
            "WordNet             WordNet             \n",
            "along               along               \n",
            "with                with                \n",
            "a                   a                   \n",
            "suite               suite               \n",
            "of                  of                  \n",
            "text                text                \n",
            "processing          processing          \n",
            "libraries           library             \n",
            "for                 for                 \n",
            "classification      classification      \n",
            "tokenization        tokenization        \n",
            "stemming            stemming            \n",
            "tagging             tagging             \n",
            "parsing             parsing             \n",
            "and                 and                 \n",
            "semantic            semantic            \n",
            "reasoning           reasoning           \n",
            "wrappers            wrapper             \n",
            "for                 for                 \n",
            "industrial-strength industrial-strength \n",
            "NLP                 NLP                 \n",
            "libraries           library             \n",
            "and                 and                 \n",
            "an                  an                  \n",
            "active              active              \n",
            "discussion          discussion          \n",
            "forum               forum               \n",
            "Thanks              Thanks              \n",
            "to                  to                  \n",
            "a                   a                   \n",
            "hands-on            hands-on            \n",
            "guide               guide               \n",
            "introducing         introducing         \n",
            "programming         programming         \n",
            "fundamentals        fundamental         \n",
            "alongside           alongside           \n",
            "topics              topic               \n",
            "in                  in                  \n",
            "computational       computational       \n",
            "linguistics         linguistics         \n",
            "plus                plus                \n",
            "comprehensive       comprehensive       \n",
            "API                 API                 \n",
            "documentation       documentation       \n",
            "NLTK                NLTK                \n",
            "is                  is                  \n",
            "suitable            suitable            \n",
            "for                 for                 \n",
            "linguists           linguist            \n",
            "engineers           engineer            \n",
            "students            student             \n",
            "educators           educator            \n",
            "researchers         researcher          \n",
            "and                 and                 \n",
            "industry            industry            \n",
            "users               user                \n",
            "alike               alike               \n",
            "NLTK                NLTK                \n",
            "is                  is                  \n",
            "available           available           \n",
            "for                 for                 \n",
            "Windows             Windows             \n",
            "Mac                 Mac                 \n",
            "OS                  OS                  \n",
            "X                   X                   \n",
            "and                 and                 \n",
            "Linux               Linux               \n",
            "Best                Best                \n",
            "of                  of                  \n",
            "all                 all                 \n",
            "NLTK                NLTK                \n",
            "is                  is                  \n",
            "a                   a                   \n",
            "free                free                \n",
            "open                open                \n",
            "source              source              \n",
            "community-driven    community-driven    \n",
            "project.NLTK        project.NLTK        \n",
            "has                 ha                  \n",
            "been                been                \n",
            "called              called              \n",
            "“                   “                   \n",
            "a                   a                   \n",
            "wonderful           wonderful           \n",
            "tool                tool                \n",
            "for                 for                 \n",
            "teaching            teaching            \n",
            "and                 and                 \n",
            "working             working             \n",
            "in                  in                  \n",
            "computational       computational       \n",
            "linguistics         linguistics         \n",
            "using               using               \n",
            "Python              Python              \n",
            "”                   ”                   \n",
            "and                 and                 \n",
            "“                   “                   \n",
            "an                  an                  \n",
            "amazing             amazing             \n",
            "library             library             \n",
            "to                  to                  \n",
            "play                play                \n",
            "with                with                \n",
            "natural             natural             \n",
            "language.           language.           \n",
            "”                   ”                   \n",
            "Natural             Natural             \n",
            "Language            Language            \n",
            "Processing          Processing          \n",
            "with                with                \n",
            "Python              Python              \n",
            "provides            provides            \n",
            "a                   a                   \n",
            "practical           practical           \n",
            "introduction        introduction        \n",
            "to                  to                  \n",
            "programming         programming         \n",
            "for                 for                 \n",
            "language            language            \n",
            "processing          processing          \n",
            "Written             Written             \n",
            "by                  by                  \n",
            "the                 the                 \n",
            "creators            creator             \n",
            "of                  of                  \n",
            "NLTK                NLTK                \n",
            "it                  it                  \n",
            "guides              guide               \n",
            "the                 the                 \n",
            "reader              reader              \n",
            "through             through             \n",
            "the                 the                 \n",
            "fundamentals        fundamental         \n",
            "of                  of                  \n",
            "writing             writing             \n",
            "Python              Python              \n",
            "programs            program             \n",
            "working             working             \n",
            "with                with                \n",
            "corpora             corpus              \n",
            "categorizing        categorizing        \n",
            "text                text                \n",
            "analyzing           analyzing           \n",
            "linguistic          linguistic          \n",
            "structure           structure           \n",
            "and                 and                 \n",
            "more                more                \n",
            "The                 The                 \n",
            "online              online              \n",
            "version             version             \n",
            "of                  of                  \n",
            "the                 the                 \n",
            "book                book                \n",
            "has                 ha                  \n",
            "been                been                \n",
            "been                been                \n",
            "updated             updated             \n",
            "for                 for                 \n",
            "Python              Python              \n",
            "3                   3                   \n",
            "and                 and                 \n",
            "NLTK                NLTK                \n",
            "3                   3                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkkPJqxNVbVj"
      },
      "source": [
        "# Stemming Vs Lemmatization\n",
        "\n",
        "Stemming dan Lemmatization keduanya menghasilkan bentuk akar dari kata-kata infleksi. Perbedaannya adalah bahwa stem mungkin bukan kata yang sebenarnya sedangkan lemma adalah kata bahasa yang sebenarnya.Lalu proses stem lebih cepat dari lemma karena base on algoritma dalam melakukan stemming sedangkan lemmatization menggunakan wordnet corpus + menentukan kata tersebut benar dalam bahasa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EDfHPcuVbVk"
      },
      "source": [
        "# Entity Masking\n",
        "Proses memasking atau menyamarkan suatu entitas dalam teks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh5_SQjXVbVk",
        "outputId": "91ef09cc-57cf-47e9-8cb2-e854d7543340"
      },
      "source": [
        "#entity masking\n",
        "import re #import regex\n",
        "email = re.compile('\\w+@\\w+\\.[a-z]{3}') #pattern untuk objek tertentu\n",
        "text2=\"to email guido, try guido@python.org or the older address guido@google.com\" \n",
        "email.findall(text2) #melakukan cek dan matching dengan pattern"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['guido@python.org', 'guido@google.com']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SopjAmU-VbVk",
        "outputId": "e020db0d-8039-4f48-d99f-434616757fb0"
      },
      "source": [
        "text_mask=email.sub('_email_',text2) #replace/subtitusi _email_ pada text2 dengan pattern yang match\n",
        "text_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'to email guido, try _email_ or the older address _email_'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN-3YAqPVbVl",
        "outputId": "67a78b85-82de-49c1-8257-26036a3e5c91"
      },
      "source": [
        "#Named Entity Recognition (NER) juga dikenal sebagai entity identification, entity chunking, dan entity extraction \n",
        "#adalah subtugas ekstraksi informasi yang berusaha untuk mencari dan mengklasifikasikan\n",
        "#entitas bernama yang disebutkan dalam teks tidak terstruktur ke dalam kategori yang telah ditentukan \n",
        "#sebelumnya seperti orang nama, organisasi, lokasi, kode medis, ekspresi waktu, jumlah, nilai moneter, persentase, dll.\n",
        "\n",
        "from nltk import ne_chunk\n",
        "NE_sent=\"The US President stays in the WHITE HOUSE\"\n",
        "NE_tokens=word_tokenize(NE_sent)\n",
        "NE_tags=nltk.pos_tag(NE_tokens)\n",
        "NE_NER=ne_chunk(NE_tags)\n",
        "print(NE_NER)\n",
        "#NE_sent2=\"Google’s CEO Sundar Pichai introduce the new Pixel 3 at New York Central Mall\"\n",
        "NE_sent2=\"sugih eat banana and chicken , when he broken heart\"\n",
        "NE_tokens2=word_tokenize(NE_sent2)\n",
        "NE_tags2=nltk.pos_tag(NE_tokens2)\n",
        "NE_NER2=ne_chunk(NE_tags2)\n",
        "print(NE_NER2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  The/DT\n",
            "  (ORGANIZATION US/NNP)\n",
            "  President/NNP\n",
            "  stays/VBZ\n",
            "  in/IN\n",
            "  the/DT\n",
            "  (FACILITY WHITE/NNP HOUSE/NNP))\n",
            "(S\n",
            "  sugih/JJ\n",
            "  eat/NN\n",
            "  banana/NN\n",
            "  and/CC\n",
            "  chicken/NN\n",
            "  ,/,\n",
            "  when/WRB\n",
            "  he/PRP\n",
            "  broken/VBD\n",
            "  heart/NN)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HkowX7JVbVm"
      },
      "source": [
        "# POS Tagger\n",
        "proses pemberian penanda part-of-speech (POS) atau kelas sintaktik atau label pada tiap kata di dalam corpus. Berikut adalah label-labelnya.\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9ORoU13VbVn",
        "outputId": "7e301525-32c5-4572-91b3-9cf28dc9834a"
      },
      "source": [
        "sent = \"Timothy is a natural when it comes to drawing\"\n",
        "sent_tokens = word_tokenize(sent)#tokenisasi terlebih dahulu\n",
        "for token in sent_tokens:\n",
        "  print(nltk.pos_tag([token]))#memakai librari untuk POS tagging\n",
        "\n",
        "sent2 = \"John is eating a delicious cake\"\n",
        "sent_tokens2 = word_tokenize(sent2)\n",
        "for token in sent_tokens2:\n",
        "  print(nltk.pos_tag([token]))  \n",
        "\n",
        "sent3 = \"Google add something on the internet\"\n",
        "sent_tokens3 = word_tokenize(sent3)\n",
        "for token in sent_tokens3:\n",
        "  print(nltk.pos_tag([token]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Timothy', 'NN')]\n",
            "[('is', 'VBZ')]\n",
            "[('a', 'DT')]\n",
            "[('natural', 'JJ')]\n",
            "[('when', 'WRB')]\n",
            "[('it', 'PRP')]\n",
            "[('comes', 'VBZ')]\n",
            "[('to', 'TO')]\n",
            "[('drawing', 'VBG')]\n",
            "[('John', 'NNP')]\n",
            "[('is', 'VBZ')]\n",
            "[('eating', 'VBG')]\n",
            "[('a', 'DT')]\n",
            "[('delicious', 'JJ')]\n",
            "[('cake', 'NN')]\n",
            "[('Google', 'NN')]\n",
            "[('add', 'VB')]\n",
            "[('something', 'NN')]\n",
            "[('on', 'IN')]\n",
            "[('the', 'DT')]\n",
            "[('internet', 'NN')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvf1qHlkVbVo"
      },
      "source": [
        "# Phrase Chunking\n",
        "Fase pemrosesan bahasa alami yang memisahkan dan menyegmentasikan kalimat menjadi sub-konstituennya, seperti kata benda, kata kerja, dan frasa preposisional, masing-masing disingkat NP, VP, dan PP. Biasanya, setiap subkontituen atau potongan dilambangkan dengan tanda kurung"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDQf5Lm8VbVo",
        "outputId": "36d24727-2e86-45f9-f871-0c9c3ce638f8"
      },
      "source": [
        "new=\"The big cat ate the little mouse who was after fresh cheese\"\n",
        "new_tokens=nltk.pos_tag(word_tokenize(new))\n",
        "new_tokens\n",
        "grammar_np=r\"NP: {<DT>?<JJ>*<NN>}\" #chunking dengan format DT JJ NN\n",
        "chunk_parser=nltk.RegexpParser(grammar_np)\n",
        "chunk_result=chunk_parser.parse(new_tokens)\n",
        "print(chunk_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  (NP The/DT big/JJ cat/NN)\n",
            "  ate/VBD\n",
            "  (NP the/DT little/JJ mouse/NN)\n",
            "  who/WP\n",
            "  was/VBD\n",
            "  after/IN\n",
            "  (NP fresh/JJ cheese/NN))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt3FJZh1VbVp",
        "outputId": "d916de29-b528-4b53-e75c-91b73ee7ed7d"
      },
      "source": [
        "new=\"The big cat ate the little mouse who was after fresh cheese\"\n",
        "new_tokens=nltk.pos_tag(word_tokenize(new))\n",
        "new_tokens\n",
        "grammar_np=r\"NP: {<NN>?<VBD>*<DT>}\" #chunking dengan format NN VBD DT\n",
        "chunk_parser=nltk.RegexpParser(grammar_np)\n",
        "chunk_result=chunk_parser.parse(new_tokens)\n",
        "print(chunk_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  (NP The/DT)\n",
            "  big/JJ\n",
            "  (NP cat/NN ate/VBD the/DT)\n",
            "  little/JJ\n",
            "  mouse/NN\n",
            "  who/WP\n",
            "  was/VBD\n",
            "  after/IN\n",
            "  fresh/JJ\n",
            "  cheese/NN)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}